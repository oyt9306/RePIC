{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fa35975102c420e9ec52932d3058bda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-08-10 10:22:10,026] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dsailyt/anaconda3/envs/vpt/bin/../lib/gcc/x86_64-conda-linux-gnu/11.2.0/../../../../x86_64-conda-linux-gnu/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/home/dsailyt/anaconda3/envs/vpt/bin/../lib/gcc/x86_64-conda-linux-gnu/11.2.0/../../../../x86_64-conda-linux-gnu/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LoRA-merged model saved to: ./qwen2.5-vl-lora-merged-qwen\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor, AutoModelForSeq2SeqLM\n",
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor\n",
    "import torch\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "base_model_id = \"Qwen/Qwen2.5-VL-7B-Instruct\"\n",
    "lora_model_id = 'your/lora/checkpoint'\n",
    "processor = AutoProcessor.from_pretrained(base_model_id)\n",
    "\n",
    "base_model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    base_model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    device_map='cuda',\n",
    ")\n",
    "\n",
    "# 4. Load and merge LoRA\n",
    "model = PeftModel.from_pretrained(base_model, lora_model_id)\n",
    "model = model.merge_and_unload() \n",
    "\n",
    "# 5. save\n",
    "output_path = \"./qwen2.5-vl-lora-merged-qwen\"\n",
    "model.save_pretrained(output_path)\n",
    "processor.save_pretrained(output_path)\n",
    "\n",
    "print(f\"✅ LoRA-merged model saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./qwen2.5-vl-lora-merged-qwen/\n",
      "./qwen2.5-vl-lora-merged-qwen/config.json\n",
      "./qwen2.5-vl-lora-merged-qwen/generation_config.json\n",
      "./qwen2.5-vl-lora-merged-qwen/model-00001-of-00004.safetensors\n",
      "./qwen2.5-vl-lora-merged-qwen/model-00002-of-00004.safetensors\n",
      "./qwen2.5-vl-lora-merged-qwen/model-00003-of-00004.safetensors\n",
      "./qwen2.5-vl-lora-merged-qwen/model-00004-of-00004.safetensors\n",
      "./qwen2.5-vl-lora-merged-qwen/model.safetensors.index.json\n",
      "./qwen2.5-vl-lora-merged-qwen/preprocessor_config.json\n",
      "./qwen2.5-vl-lora-merged-qwen/tokenizer_config.json\n",
      "./qwen2.5-vl-lora-merged-qwen/special_tokens_map.json\n",
      "./qwen2.5-vl-lora-merged-qwen/added_tokens.json\n",
      "./qwen2.5-vl-lora-merged-qwen/vocab.json\n",
      "./qwen2.5-vl-lora-merged-qwen/merges.txt\n",
      "./qwen2.5-vl-lora-merged-qwen/tokenizer.json\n",
      "./qwen2.5-vl-lora-merged-qwen/chat_template.json\n"
     ]
    }
   ],
   "source": [
    "!tar -cvf qwen2.5-vl-lora-merged.tar ./qwen2.5-vl-lora-merged-qwen/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
